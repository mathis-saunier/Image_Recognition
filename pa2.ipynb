{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf76747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8adc7398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_image_size(dataset_path):\n",
    "    widths, heights = [], []\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_name in os.listdir(class_path):\n",
    "                try:\n",
    "                    img_path = os.path.join(class_path, img_name)\n",
    "                    with Image.open(img_path) as img:\n",
    "                        w, h = img.size\n",
    "                        widths.append(w)\n",
    "                        heights.append(h)\n",
    "                except:\n",
    "                    continue\n",
    "    avg_width = int(np.mean(widths))\n",
    "    avg_height = int(np.mean(heights))\n",
    "    return avg_width, avg_height\n",
    "\n",
    "def load_caltech20_dataset(dataset_path, resize=False):\n",
    "    avg_w, avg_h = get_average_image_size(dataset_path)\n",
    "    data, labels = [], []\n",
    "    classes = sorted(os.listdir(dataset_path))\n",
    "\n",
    "    for label, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert(\"RGB\")\n",
    "                    if resize:\n",
    "                        img = img.resize((avg_w, avg_h))\n",
    "                    data.append(np.array(img))\n",
    "                    labels.append(label)\n",
    "                except:\n",
    "                    print(f\"Erreur avec {img_path}\")\n",
    "\n",
    "    return np.array(data), np.array(labels), classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14171815",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1051,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X, y, class_names = \u001b[43mload_caltech20_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcaltech20\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(X.shape, y.shape)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mload_caltech20_dataset\u001b[39m\u001b[34m(dataset_path, resize)\u001b[39m\n\u001b[32m     35\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     36\u001b[39m                 \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mErreur avec \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m, np.array(labels), classes\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1051,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "X, y, class_names = load_caltech20_dataset(\"caltech20\")\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad2bfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'images : 1051\n",
      "Nombre de classes : 20\n",
      "Exemples de classes : ['ant', 'beaver', 'brontosaurus', 'cannon', 'chair']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nombre d'images : {len(X)}\")\n",
    "print(f\"Nombre de classes : {len(class_names)}\")\n",
    "print(f\"Exemples de classes : {class_names[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edc86548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 840\n",
      "Testing set size: 211\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325eef93",
   "metadata": {},
   "source": [
    "pip install opencv-contrib-python scikit-learn\n",
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "947e0617",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libGL.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: libGL.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def extract_sift_features(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return descriptors\n",
    "\n",
    "def load_descriptors(image_paths):\n",
    "    all_desc = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        desc = extract_sift_features(img)\n",
    "        if desc is not None:\n",
    "            all_desc.append(desc)\n",
    "    return all_desc\n",
    "\n",
    "def sample_descriptors(all_descriptors, max_samples=10000):\n",
    "    desc_stack = np.vstack(all_descriptors)\n",
    "    indices = np.random.choice(len(desc_stack), min(max_samples, len(desc_stack)), replace=False)\n",
    "    return desc_stack[indices]\n",
    "\n",
    "def reduce_dimensionality(descriptors, n_components=64):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(descriptors), pca\n",
    "\n",
    "def build_codebook(descriptors, k=100):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(descriptors)\n",
    "    return kmeans\n",
    "\n",
    "def compute_bow_histogram(image, sift, pca, kmeans):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, desc = sift.detectAndCompute(gray, None)\n",
    "    if desc is None:\n",
    "        return np.zeros(kmeans.n_clusters)\n",
    "    desc = pca.transform(desc)\n",
    "    labels = kmeans.predict(desc)\n",
    "    hist, _ = np.histogram(labels, bins=np.arange(kmeans.n_clusters + 1))\n",
    "    return hist / np.linalg.norm(hist)  # Normalize\n",
    "\n",
    "def encode_dataset(image_paths, sift, pca, kmeans):\n",
    "    features = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path)\n",
    "        hist = compute_bow_histogram(img, sift, pca, kmeans)\n",
    "        features.append(hist)\n",
    "    return np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e32ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
